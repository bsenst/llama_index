{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530c973e-916d-4c9e-9365-e2d5306d7e3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Outlines Pydantic Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18461ba1-6978-4b5b-861e-6dceec36857b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate structured data with [**outlines**](https://github.com/normal-computing/outlines) via LlamaIndex.  \n",
    "\n",
    "(Taken from the repo README): Outlines ã€° helps developers guide text generation to build robust interfaces with external systems. Provides generation methods that guarantee that the output will match a regular expressions, or follow a JSON schema.\n",
    "\n",
    "In this example we show how we can use `outlines` to extract structured pydantic objects from unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ca640-d894-44d5-94fd-4e1e973bd7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install `outlines` if you haven't done so already\n",
    "!pip install outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a83b49-5c34-45d5-8cf4-62f348fb1299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "\n",
    "from llama_index.program import OutlinesProgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563f1ba-8086-4dcc-ba35-bfda31c45ae4",
   "metadata": {},
   "source": [
    "Define output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42053ea8-2580-4639-9dcf-566e8427c44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Weapon(str, Enum):\n",
    "    sword = \"sword\"\n",
    "    axe = \"axe\"\n",
    "    mace = \"mace\"\n",
    "    spear = \"spear\"\n",
    "    bow = \"bow\"\n",
    "    crossbow = \"crossbow\"\n",
    "\n",
    "\n",
    "class Armor(str, Enum):\n",
    "    leather = \"leather\"\n",
    "    chainmail = \"chainmail\"\n",
    "    plate = \"plate\"\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    armor: Armor\n",
    "    weapon: Weapon\n",
    "    strength: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afff44e-a746-4b9f-85a9-72058bcdd29f",
   "metadata": {},
   "source": [
    "Define outlines pydantic program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe756697-c299-4f9a-a108-944b6693f824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import outlines.models as models\n",
    "\n",
    "program = OutlinesProgram.from_defaults(\n",
    "    output_cls=Character,\n",
    "    prompt_template_str=\"{input_str}\",\n",
    "    llm=models.OpenAICompletion(\"gpt-3.5-turbo\", max_tokens=256, temperature=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be01dc-433e-4485-bab0-36a04c3afbcb",
   "metadata": {},
   "source": [
    "Run program to get structured output.  \n",
    "Text highlighted in blue is variables specified by us, text highlighted in green is generated by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe8c178-a818-429c-bd9d-e9395a47aa30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Character',\n",
       " 'type': 'object',\n",
       " 'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "  'age': {'title': 'Age', 'type': 'integer'},\n",
       "  'armor': {'$ref': '#/$defs/Armor'},\n",
       "  'weapon': {'$ref': '#/$defs/Weapon'},\n",
       "  'strength': {'title': 'Strength', 'type': 'integer'}},\n",
       " 'required': ['name', 'age', 'armor', 'weapon', 'strength'],\n",
       " '$defs': {'Armor': {'title': 'Armor',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['leather', 'chainmail', 'plate'],\n",
       "   'type': 'string'},\n",
       "  'Weapon': {'title': 'Weapon',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['sword', 'axe', 'mace', 'spear', 'bow', 'crossbow'],\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Character.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd36441e-fb9b-44a6-8748-24e2941b5768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model = models.transformers(\"gpt2-medium\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mOpenAICompletion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCharacter\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me a character description\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/outlines/text/generate/regex.py:230\u001b[0m, in \u001b[0;36mjson\u001b[0;34m(model, schema, max_tokens)\u001b[0m\n\u001b[1;32m    226\u001b[0m     schema \u001b[38;5;241m=\u001b[39m dumps(schema\u001b[38;5;241m.\u001b[39mmodel_json_schema())\n\u001b[1;32m    228\u001b[0m regex_str \u001b[38;5;241m=\u001b[39m build_regex_from_schema(schema)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRegex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/outlines/text/generate/regex.py:29\u001b[0m, in \u001b[0;36mRegex.__init__\u001b[0;34m(self, model, regex_string, max_tokens)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, regex_string: \u001b[38;5;28mstr\u001b[39m, max_tokens: Optional[\u001b[38;5;28mint\u001b[39m]):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mvocabulary\n\u001b[1;32m     32\u001b[0m     sorted_vocabulary \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m         model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_token_to_string(k)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(vocabulary\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m kv: kv[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     35\u001b[0m     ]\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/outlines/text/generate/continuation.py:23\u001b[0m, in \u001b[0;36mContinuation.__init__\u001b[0;34m(self, model, max_tokens, stop)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m, model, max_tokens: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, stop: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m ):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m     25\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stop, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/outlines/text/generate/sequence.py:22\u001b[0m, in \u001b[0;36mSequence.__init__\u001b[0;34m(self, model, max_tokens)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a `Sequence` instance.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens \u001b[38;5;241m=\u001b[39m max_tokens\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id, device\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "import outlines.models as models\n",
    "import outlines.text.generate as generate\n",
    "\n",
    "# model = models.transformers(\"gpt2-medium\")\n",
    "model = models.OpenAICompletion(\"gpt-3.5-turbo\", max_tokens=256, temperature=0.1)\n",
    "\n",
    "sequence = generate.json(model, Character)(\"Give me a character description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d02228-2907-4810-932e-83ec9fc71f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = program(input_str=\"Generate a random character description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec0777-28d5-494b-b419-daf6bce2b20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "The output is a valid Pydantic object that we can then use to call functions/APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51bcf4-e7df-47b9-b380-8e5b900a31e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
